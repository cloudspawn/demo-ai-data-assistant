# AI-Powered Data Assistant

Multi-agent AI system for accelerating Data Engineering workflows.

## Status
ğŸš§ In Development - Phase 3 Complete (SQL + Quality + Multi-Agent Debugger)

## Stack
- Python 3.12
- FastAPI (API REST)
- LangGraph (multi-agent orchestration)
- Ollama + llama3.1 (local LLM)
- DuckDB (data warehouse)
- pytest (testing)

## Features

### âœ… Implemented
- [x] SQL Query Generator (Agent 1)
- [x] Quality Check Generator (Agent 2)
- [x] Pipeline Debugger (Agent 3 - Multi-agent with LangGraph)
- [x] FastAPI REST API
- [x] Health check endpoints
- [x] Auto-generated Swagger UI
- [x] Full test coverage (41 tests)

### ğŸš§ In Progress
- [ ] Documentation Generator (Agent 4 - optional)

## Quick Start

### Prerequisites
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull llama3.1 model
ollama pull llama3.1

# Start Ollama server
ollama serve
```

### Installation
```bash
# Clone repository
git clone <your-repo-url>
cd demo-ai-data-assistant

# Install dependencies with uv
uv sync --extra dev

# Copy environment template
cp .env.example .env

# Edit .env with your Ollama URL (default: localhost:11434)
# If VM â†’ PC setup: OLLAMA_BASE_URL=http://192.168.x.x:11434
```

### Create Sample Data
```bash
# Create sample DuckDB database
uv run python scripts/create_sample_data.py
```

### Run API Server
```bash
# Start FastAPI server
uv run uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### Test the API

**Option 1: Swagger UI (Recommended)**
```
Open: http://localhost:8000/docs
```

**Option 2: curl**
```bash
# Health check
curl http://localhost:8000/

# Generate SQL
curl -X POST http://localhost:8000/api/sql/generate \
  -H "Content-Type: application/json" \
  -d '{"question": "Show me traffic trends in Paris"}'

# Suggest quality checks
curl -X POST http://localhost:8000/api/quality/suggest \
  -H "Content-Type: application/json" \
  -d '{
    "table_name": "analytics_events_daily",
    "table_schema": {
      "event_date": "DATE",
      "city": "VARCHAR",
      "event_count": "INTEGER"
    }
  }'

# Debug pipeline error
curl -X POST http://localhost:8000/api/debug/pipeline \
  -H "Content-Type: application/json" \
  -d '{
    "error_log": "PermissionError: Permission denied",
    "dag_code": "with open(\"/path/file\") as f: pass"
  }'
```

**Option 3: Direct agent test**
```bash
# Test SQL Generator
uv run python -m agents.sql_generator

# Test Quality Checker
uv run python -m agents.quality_checker

# Test Pipeline Debugger
uv run python -m agents.debugger
```

## Testing

### Run all tests
```bash
uv run pytest
```

### Run specific test file
```bash
uv run pytest tests/test_sql_generator.py
uv run pytest tests/test_quality_checker.py
uv run pytest tests/test_debugger.py
uv run pytest tests/test_api.py
```

## API Endpoints

### `GET /`
Health check with Ollama connectivity status

### `GET /health`
Simple health check

### `POST /api/sql/generate`
Generate and execute SQL from natural language

**Request:**
```json
{
  "question": "Show me traffic trends in Paris last week"
}
```

**Response:**
```json
{
  "success": true,
  "sql": "SELECT ...",
  "results": [...],
  "row_count": 3,
  "explanation": "This query..."
}
```

### `POST /api/quality/suggest`
Generate data quality check suggestions from table schema

**Request:**
```json
{
  "table_name": "analytics_events_daily",
  "table_schema": {
    "event_date": "DATE",
    "city": "VARCHAR",
    "event_count": "INTEGER",
    "avg_value": "DOUBLE"
  }
}
```

**Response:**
```json
{
  "success": true,
  "table_name": "analytics_events_daily",
  "checks": [
    {
      "check_name": "event_date_not_null",
      "column": "event_date",
      "check_type": "null_check",
      "severity": "critical",
      "description": "event_date should never be NULL",
      "python_code": "assert df['event_date'].notna().all()"
    }
  ],
  "check_count": 5
}
```

### `POST /api/debug/pipeline`
Debug data pipeline errors using multi-agent analysis (LangGraph)

**Request:**
```json
{
  "error_log": "[2026-01-25] ERROR - PermissionError: Permission denied: '/opt/airflow/data/raw/events.csv'",
  "dag_code": "from airflow import DAG\n\ndef extract_data():\n    with open('/opt/airflow/data/raw/events.csv', 'r') as f:\n        data = f.read()"
}
```

**Response:**
```json
{
  "success": true,
  "diagnosis": {
    "error_type": "PermissionError",
    "root_cause": "File permissions issue..."
  },
  "solution": {
    "steps": "1. Change ownership...",
    "commands": ["sudo chown airflow:airflow /opt/airflow/data/raw"],
    "explanation": "This fixes the permissions..."
  },
  "prevention": "Set correct permissions from start...",
  "agent_workflow": [
    "Log Analyzer: Identified PermissionError",
    "Code Checker: Analyzed code...",
    "Solution Generator: Generated fix"
  ]
}
```

## Architecture

### Multi-Agent System (Pipeline Debugger)

The Pipeline Debugger uses **LangGraph** to orchestrate 3 specialized agents:
```
Error Log + DAG Code
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Log Analyzer    â”‚ â†’ Identifies error type
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Checker    â”‚ â†’ Analyzes root cause
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Solution Generatorâ”‚ â†’ Proposes fix + commands
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  Diagnosis + Solution
```

Each agent specializes in one task, improving accuracy and quality of responses.

## Project Structure
```
demo-ai-data-assistant/
â”œâ”€â”€ agents/              # AI Agents
â”‚   â”œâ”€â”€ sql_generator.py # Agent 1: SQL Generator
â”‚   â”œâ”€â”€ quality_checker.py # Agent 2: Quality Checker
â”‚   â””â”€â”€ debugger.py      # Agent 3: Pipeline Debugger (LangGraph)
â”œâ”€â”€ api/                 # FastAPI application
â”‚   â”œâ”€â”€ main.py         # App entry point
â”‚   â”œâ”€â”€ models.py       # Pydantic models
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ sql.py      # SQL endpoints
â”‚       â”œâ”€â”€ quality.py  # Quality endpoints
â”‚       â””â”€â”€ debugger.py # Debugger endpoints
â”œâ”€â”€ config/              # Configuration
â”‚   â””â”€â”€ settings.py     # Pydantic settings
â”œâ”€â”€ tests/               # Test suite (41 tests)
â”‚   â”œâ”€â”€ conftest.py     # Pytest fixtures
â”‚   â”œâ”€â”€ test_sql_generator.py
â”‚   â”œâ”€â”€ test_quality_checker.py
â”‚   â”œâ”€â”€ test_debugger.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ scripts/             # Utility scripts
â”‚   â””â”€â”€ create_sample_data.py
â”œâ”€â”€ data/                # Data files (gitignored)
â”œâ”€â”€ .env.example        # Environment template
â””â”€â”€ pyproject.toml      # Dependencies
```

## Configuration

### Ollama (Default - Local)
```bash
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1
```

### Network Setup (VM â†’ PC with GPU)
If running on VM and Ollama on separate PC:
```bash
OLLAMA_BASE_URL=http://192.168.x.x:11434  # Replace x.x with PC IP
```

## Development

### Run tests
```bash
uv run pytest
```

### Code formatting
```bash
uv run ruff check .
uv run ruff format .
```

## What I Learned

### Multi-Agent Orchestration
- Built a LangGraph-powered multi-agent system
- Each agent specializes in one task (separation of concerns)
- Agents share state and collaborate sequentially
- Better results than single large prompts

### LLM Integration
- Integrated Ollama for local, cost-free LLM inference
- Prompt engineering for structured outputs
- Parsing and validating LLM responses
- Error handling and fallback strategies

### API Design
- RESTful API with FastAPI
- Pydantic models for request/response validation
- Dependency injection for settings and agents
- Auto-generated OpenAPI documentation

### Testing Strategy
- Unit tests with mocked LLM calls
- Integration tests for end-to-end workflows
- Test fixtures for reusable test data
- 41 tests covering all agents and endpoints

## License
MIT