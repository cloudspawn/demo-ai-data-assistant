# AI-Powered Data Assistant

Multi-agent AI system for accelerating Data Engineering workflows.

## Status
ðŸš§ In Development - Phase 1 Complete (SQL Generator + API + Tests)

## Stack
- Python 3.12
- FastAPI (API REST)
- LangGraph (multi-agent orchestration)
- Ollama + llama3.1 (local LLM)
- DuckDB (data warehouse)
- pytest (testing)

## Features

### âœ… Implemented
- [x] SQL Query Generator (Agent 1)
- [x] FastAPI REST API
- [x] Health check endpoints
- [x] Auto-generated Swagger UI
- [x] Unit and integration tests
- [x] Test fixtures and mocks

### ðŸš§ In Progress
- [ ] Quality Check Generator (Agent 2)
- [ ] Pipeline Debugger (Agent 3 - multi-agent)
- [ ] Documentation Generator (Agent 4 - optional)

## Quick Start

### Prerequisites
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull llama3.1 model
ollama pull llama3.1

# Start Ollama server
ollama serve
```

### Installation
```bash
# Clone repository
git clone <your-repo-url>
cd demo-ai-data-assistant

# Install dependencies with uv
uv sync

# Copy environment template
cp .env.example .env

# Edit .env with your Ollama URL (default: localhost:11434)
# If VM â†’ PC setup: OLLAMA_BASE_URL=http://192.168.1.10:11434
```

### Create Sample Data
```bash
# Create sample DuckDB database
uv run python scripts/create_sample_data.py
```

### Run API Server
```bash
# Start FastAPI server
uv run uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### Test the API

**Option 1: Swagger UI (Recommended)**
```
Open: http://localhost:8000/docs
```

**Option 2: curl**
```bash
# Health check
curl http://localhost:8000/

# Generate SQL
curl -X POST http://localhost:8000/api/sql/generate \
  -H "Content-Type: application/json" \
  -d '{"question": "Show me traffic trends in Paris"}'
```

**Option 3: Direct agent test**
```bash
uv run python -m agents.sql_generator
```

## Testing

### Run all tests
```bash
uv run pytest
```

### Run specific test file
```bash
uv run pytest tests/test_sql_generator.py
uv run pytest tests/test_api.py
```

### Run with coverage
```bash
uv run pytest --cov=agents --cov=api
```

## API Endpoints

### `GET /`
Health check with Ollama connectivity status

### `GET /health`
Simple health check

### `POST /api/sql/generate`
Generate and execute SQL from natural language

**Request:**
```json
{
  "question": "Show me traffic trends in Paris last week"
}
```

**Response:**
```json
{
  "success": true,
  "question": "Show me traffic trends in Paris last week",
  "sql": "SELECT event_date, city, avg_value FROM analytics_events_daily WHERE city = 'Paris' AND category = 'traffic' ORDER BY event_date",
  "results": [...],
  "row_count": 3,
  "explanation": "This query retrieves traffic trends for Paris..."
}
```

## Project Structure
```
demo-ai-data-assistant/
â”œâ”€â”€ agents/              # AI Agents
â”‚   â””â”€â”€ sql_generator.py # Agent 1: SQL Generator
â”œâ”€â”€ api/                 # FastAPI application
â”‚   â”œâ”€â”€ main.py         # App entry point
â”‚   â”œâ”€â”€ models.py       # Pydantic models
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ sql.py      # SQL endpoints
â”œâ”€â”€ config/              # Configuration
â”‚   â””â”€â”€ settings.py     # Pydantic settings
â”œâ”€â”€ tests/               # Test suite
â”‚   â”œâ”€â”€ conftest.py     # Pytest fixtures
â”‚   â”œâ”€â”€ test_sql_generator.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ scripts/             # Utility scripts
â”‚   â””â”€â”€ create_sample_data.py
â”œâ”€â”€ data/                # Data files (gitignored)
â”œâ”€â”€ .env.example        # Environment template
â””â”€â”€ pyproject.toml      # Dependencies
```

## Configuration

### Ollama (Default - Local)
```bash
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1
```

### Network Setup (VM â†’ PC with GPU)
If running on VM and Ollama on separate PC:
```bash
OLLAMA_BASE_URL=http://192.168.x.x:11434  # Replace with PC IP
```

## Development

### Run tests
```bash
uv run pytest
```

### Code formatting
```bash
uv run ruff check .
uv run ruff format .
```

## License
MIT